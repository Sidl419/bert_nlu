{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект по курсу ММОТ 2023\n",
    "\n",
    "### Сидоров Леонид 617 ВМК МГУ\n",
    "\n",
    "Темой моего проекта было `Обучение BERT классификации с информацией из базы знаний`, постановка задачи заключается в следующем\n",
    "\n",
    "```\n",
    "Найти датасет с текстами, содержащими большое число именованых сущностей \n",
    "(можно найти готовый или разметить сущности самому, на основе базы знаний).\n",
    "Провести эксперименты:\n",
    "оценить качество классификации на сырых документах\n",
    "оценить качество классификации при одновременном обучении разметке и классификации текстов\n",
    "оценить качество классификации, когда нужные слова в тексте помечаются \"маркерами\"\n",
    "```\n",
    "\n",
    "В поисках подходящего набора данных я решил немного переформулирвать задачу и свёл её к задаче NLU. В ней есть два таргета:\n",
    "\n",
    "1. интент пользователя, то есть его основное намеренние (задача multi label классификации);\n",
    "2. слоты, то есть важные смысловые части запроса, которые важны для реализации интента (задача тегирования последовательности, NER).\n",
    "\n",
    "Выделять слоты можно различными способами, но было выбрано тегирование: исходные слоты переводятся в BIO-разметку, по которой решается задача NER.\n",
    "\n",
    "Одно наблюдение имеет следующий вид\n",
    "\n",
    "```JSON\n",
    "{\n",
    "    \"text\": \"Yes, from 25 past 23 on\",\n",
    "    \"intents\": [\n",
    "      \"affirm\"\n",
    "    ],\n",
    "    \"slots\": {\n",
    "      \"time_from\": {\n",
    "        \"text\": \"25 past 23\",\n",
    "        \"span\": [\n",
    "          10,\n",
    "          20\n",
    "        ],\n",
    "        \"value\": {\n",
    "          \"hour\": 23,\n",
    "          \"minute\": 25\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "```\n",
    "\n",
    "В общем случае интентов может быть больше одного, в нашем примере это `affirm`, то есть подтверждение. Слотов в одном тексте также может быть много, нас интересует не конкретное его значение, а тип и расположение по токенам. То есть слотовую разметку данного текста можно представить в виде\n",
    "\n",
    "```\n",
    "O O B-time_from I-time_from I-time_from O\n",
    "```\n",
    "\n",
    "Который говорит нам, что в конце предложения клиент говорил о времени, в которое он подтвердил встречу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer, TrainingArguments, Trainer, \\\n",
    "    DataCollatorForTokenClassification, DataCollatorWithPadding, \\\n",
    "    AutoModelForTokenClassification, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выгрузка набора данных\n",
    "\n",
    "Рассматриваемый набор данных состоит из обращений пользователей в службу поддержки в двух разных сферах услуг: отелях и банках.\n",
    "\n",
    "Данные было сложно размечать, поэтому его размер сильно ограничен, всего порядка 220 сложно структурированных наблюдений. Поэтому замерять качество мы будем с помощью усреднённой валидации на 20 фолдах, как было предложено авторами набора данных [здесь](https://github.com/PolyAI-LDN/task-specific-datasets/tree/master/nlupp). Выборка делится на 20 фолдов, после чего последовательно 2 подряд идущих фолда используется для валидации, а все остальные для обучения, итого получаем 10 наборов данных для обучения и валидации. Эти 2 фолда относятся к двум разным предметным областям.\n",
    "\n",
    "Использование же больших предобученных моделей, таких как BERT, поможет нам обобщиться даже для такого небольшого набора наблюдений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from data_loader import DataLoader\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "tokenizer_params = dict(truncation=True)\n",
    "\n",
    "loader = DataLoader(\"./data\", tokenizer, tokenizer_params)\n",
    "datasets = loader.get_data_for_experiment(domain=\"all\", regime=\"large\")\n",
    "info_columns = [\"text\", \"intents\", \"tagger\", \"tokens\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Раздельная классификация интентов и поиск слотов\n",
    "\n",
    "В этом разделе мы решим две основные задачи NLU по отдельности, а именно сначала решим задачу NER, где в качестве сущностей будут выступать слоты в BIO разметке, а потом задачу многоклассовой классификации интентов, в которой одной фразе может быть сопоставлено сразу несколько намерений пользователя.\n",
    "\n",
    "Для теггирования была выбрана `AutoModelForTokenClassification`, стандартная обёртка вокруг модели DistilBERT из библиотеки `HuggingFace`. Большая часть логирования была отключена, потому что при обучении 10 версий модели информации становится слишком много. Однако выключить вообще все выводы в HuggingFace оказалось нетривиальной задачей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\"distilbert-finetuned\",\n",
    "                        learning_rate=1e-5,\n",
    "                        optim=\"adamw_torch_fused\",\n",
    "                        per_device_train_batch_size=128,\n",
    "                        per_device_eval_batch_size=128,\n",
    "                        num_train_epochs=10,\n",
    "                        weight_decay=0.01,\n",
    "                        warmup_steps = 10,\n",
    "                        lr_scheduler_type = 'linear',\n",
    "                        evaluation_strategy=\"no\",\n",
    "                        #eval_steps=10,\n",
    "                        seed=42,\n",
    "                        fp16=True,\n",
    "                        logging_strategy='no',\n",
    "                        #logging_steps=200,\n",
    "                        save_strategy=\"no\",\n",
    "                        disable_tqdm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 39.844, 'train_samples_per_second': 696.717, 'train_steps_per_second': 5.522, 'train_loss': 0.8640869834206321, 'epoch': 10.0}\n",
      "{'eval_loss': 0.46589499711990356, 'eval_tagger_precision': 0.3181818181818182, 'eval_tagger_recall': 0.2962962962962963, 'eval_tagger_f1': 0.30684931506849317, 'eval_tagger_accuracy': 0.8907395069953364, 'eval_runtime': 0.1674, 'eval_samples_per_second': 1815.626, 'eval_steps_per_second': 17.917, 'epoch': 10.0}\n",
      "{'train_runtime': 40.5591, 'train_samples_per_second': 683.694, 'train_steps_per_second': 5.424, 'train_loss': 0.8749995838512074, 'epoch': 10.0}\n",
      "{'eval_loss': 0.3664020001888275, 'eval_tagger_precision': 0.41975308641975306, 'eval_tagger_recall': 0.37158469945355194, 'eval_tagger_f1': 0.39420289855072466, 'eval_tagger_accuracy': 0.914079648792725, 'eval_runtime': 0.182, 'eval_samples_per_second': 1686.768, 'eval_steps_per_second': 16.483, 'epoch': 10.0}\n",
      "{'train_runtime': 40.0193, 'train_samples_per_second': 691.416, 'train_steps_per_second': 5.497, 'train_loss': 0.8695721019398083, 'epoch': 10.0}\n",
      "{'eval_loss': 0.4268594980239868, 'eval_tagger_precision': 0.4030612244897959, 'eval_tagger_recall': 0.3872549019607843, 'eval_tagger_f1': 0.395, 'eval_tagger_accuracy': 0.9045241809672387, 'eval_runtime': 0.1807, 'eval_samples_per_second': 1732.57, 'eval_steps_per_second': 16.606, 'epoch': 10.0}\n",
      "{'train_runtime': 40.3786, 'train_samples_per_second': 687.245, 'train_steps_per_second': 5.448, 'train_loss': 0.8711567271839489, 'epoch': 10.0}\n",
      "{'eval_loss': 0.41637593507766724, 'eval_tagger_precision': 0.47337278106508873, 'eval_tagger_recall': 0.4020100502512563, 'eval_tagger_f1': 0.43478260869565216, 'eval_tagger_accuracy': 0.9111331351172778, 'eval_runtime': 0.2333, 'eval_samples_per_second': 1307.501, 'eval_steps_per_second': 12.861, 'epoch': 10.0}\n",
      "{'train_runtime': 40.0525, 'train_samples_per_second': 690.844, 'train_steps_per_second': 5.493, 'train_loss': 0.8635486255992543, 'epoch': 10.0}\n",
      "{'eval_loss': 0.4837591052055359, 'eval_tagger_precision': 0.4213197969543147, 'eval_tagger_recall': 0.36403508771929827, 'eval_tagger_f1': 0.3905882352941177, 'eval_tagger_accuracy': 0.8885419918826101, 'eval_runtime': 0.2179, 'eval_samples_per_second': 1436.564, 'eval_steps_per_second': 13.769, 'epoch': 10.0}\n",
      "{'train_runtime': 40.5072, 'train_samples_per_second': 685.064, 'train_steps_per_second': 5.431, 'train_loss': 0.8698626431551847, 'epoch': 10.0}\n",
      "{'eval_loss': 0.4206540584564209, 'eval_tagger_precision': 0.4431818181818182, 'eval_tagger_recall': 0.4020618556701031, 'eval_tagger_f1': 0.42162162162162165, 'eval_tagger_accuracy': 0.9091819699499165, 'eval_runtime': 0.2298, 'eval_samples_per_second': 1327.117, 'eval_steps_per_second': 13.054, 'epoch': 10.0}\n",
      "{'train_runtime': 40.8365, 'train_samples_per_second': 677.825, 'train_steps_per_second': 5.387, 'train_loss': 0.8742040460759943, 'epoch': 10.0}\n",
      "{'eval_loss': 0.3888876140117645, 'eval_tagger_precision': 0.46745562130177515, 'eval_tagger_recall': 0.4010152284263959, 'eval_tagger_f1': 0.4316939890710383, 'eval_tagger_accuracy': 0.9147509578544061, 'eval_runtime': 0.181, 'eval_samples_per_second': 1723.5, 'eval_steps_per_second': 16.572, 'epoch': 10.0}\n",
      "{'train_runtime': 40.7942, 'train_samples_per_second': 679.508, 'train_steps_per_second': 5.393, 'train_loss': 0.8716388355601917, 'epoch': 10.0}\n",
      "{'eval_loss': 0.41202080249786377, 'eval_tagger_precision': 0.3879781420765027, 'eval_tagger_recall': 0.3333333333333333, 'eval_tagger_f1': 0.3585858585858586, 'eval_tagger_accuracy': 0.9056482670089859, 'eval_runtime': 0.1942, 'eval_samples_per_second': 1586.362, 'eval_steps_per_second': 15.452, 'epoch': 10.0}\n",
      "{'train_runtime': 40.197, 'train_samples_per_second': 688.857, 'train_steps_per_second': 5.473, 'train_loss': 0.8656234741210938, 'epoch': 10.0}\n",
      "{'eval_loss': 0.45712810754776, 'eval_tagger_precision': 0.37623762376237624, 'eval_tagger_recall': 0.36363636363636365, 'eval_tagger_f1': 0.36982968369829683, 'eval_tagger_accuracy': 0.900277863538129, 'eval_runtime': 0.2056, 'eval_samples_per_second': 1512.839, 'eval_steps_per_second': 14.593, 'epoch': 10.0}\n",
      "{'train_runtime': 41.0231, 'train_samples_per_second': 677.179, 'train_steps_per_second': 5.363, 'train_loss': 0.8704843694513494, 'epoch': 10.0}\n",
      "{'eval_loss': 0.40177100896835327, 'eval_tagger_precision': 0.30057803468208094, 'eval_tagger_recall': 0.3058823529411765, 'eval_tagger_f1': 0.3032069970845481, 'eval_tagger_accuracy': 0.9066666666666666, 'eval_runtime': 0.1799, 'eval_samples_per_second': 1678.974, 'eval_steps_per_second': 16.679, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "eval_loss                     0.423975\n",
       "eval_tagger_precision         0.401112\n",
       "eval_tagger_recall            0.362711\n",
       "eval_tagger_f1                0.380636\n",
       "eval_tagger_accuracy          0.904554\n",
       "eval_runtime                  0.197180\n",
       "eval_samples_per_second    1580.782100\n",
       "eval_steps_per_second        15.398600\n",
       "epoch                        10.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metrics import ner_metrics\n",
    "\n",
    "tagger_result = defaultdict(list)\n",
    "\n",
    "for fold_dataset in datasets.values():\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased\",\n",
    "        id2label=loader.index2tag,\n",
    "        label2id=loader.tag2index\n",
    "    ).to('cuda')\n",
    "    \n",
    "    train_dataset = fold_dataset['train'].remove_columns(info_columns + [\"classification_labels\"]).rename_column(\"tagging_labels\", \"labels\")\n",
    "    test_dataset = fold_dataset['test'].remove_columns(info_columns + [\"classification_labels\"]).rename_column(\"tagging_labels\", \"labels\")\n",
    "\n",
    "    trainer = Trainer(model=model,\n",
    "                    args=args,\n",
    "                    train_dataset = train_dataset,\n",
    "                    eval_dataset = test_dataset,\n",
    "                    data_collator=DataCollatorForTokenClassification(tokenizer=tokenizer),\n",
    "                    compute_metrics=ner_metrics,\n",
    "                    tokenizer=tokenizer)\n",
    "\n",
    "    trainer.train()\n",
    "    for name, val in trainer.evaluate().items():\n",
    "        if val != 'epoch':\n",
    "            tagger_result[name].append(val)\n",
    "\n",
    "tagger_result = pd.DataFrame(tagger_result)\n",
    "tagger_result.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В табличке выше мы получили усреднённые значения метрик классификации токенов по всем 10 моделям. Полученные метрики пока мало что нам говорят (кроме того, что среднее качество весьма скудное), но мы будем использовать их в качестве бейзлайна при сравнении с другими подходами. Также мы можем заметить, что метрики на разных фолдах достаточно сильно различаются, в некоторых случаях расхождение может достигнуть 30%.\n",
    "\n",
    "Задача классификации документов является для нас основной, поточу что именно она будет решаться на третем этапе этой работы, а именно использовании дополнительных признаков в модели в виде газетиров.\n",
    "\n",
    "---\n",
    "\n",
    "Газетиры (gazetteers) - это фактически добавление каких-то дополнительных признаков к токенам или их эмбедингам. Ясно, что при использовании BERT модификация эмбедингов сломает претрейн модели, поэтому в нашем случае стоит добавлять признаки уже к выходным эмбедингам берта, конкретные реализации будут рассмотрены в конце ноутбука.\n",
    "\n",
    "---\n",
    "\n",
    "Для теггирования была выбрана `AutoModelForSequenceClassification`, тоже стандартная обёртка вокруг модели DistilBERT из библиотеки `HuggingFace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\"distilbert-finetuned\",\n",
    "                        learning_rate=1e-5,\n",
    "                        optim=\"adamw_torch_fused\",\n",
    "                        per_device_train_batch_size=128,\n",
    "                        per_device_eval_batch_size=128,\n",
    "                        num_train_epochs=15,            # больше эпох\n",
    "                        weight_decay=0.01,\n",
    "                        warmup_steps = 10,\n",
    "                        lr_scheduler_type = 'linear',\n",
    "                        evaluation_strategy=\"no\",\n",
    "                        #eval_steps=10,\n",
    "                        seed=42,\n",
    "                        fp16=True,\n",
    "                        logging_strategy='no',\n",
    "                        #logging_steps=200,\n",
    "                        save_strategy=\"no\",\n",
    "                        disable_tqdm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 62.7008, 'train_samples_per_second': 664.106, 'train_steps_per_second': 5.263, 'train_loss': 0.37494384303237455, 'epoch': 15.0}\n",
      "{'eval_loss': 0.2475365549325943, 'eval_classification_roc_auc': 0.626742329640797, 'eval_runtime': 0.1331, 'eval_samples_per_second': 2284.582, 'eval_steps_per_second': 22.545, 'epoch': 15.0}\n",
      "{'train_runtime': 61.8479, 'train_samples_per_second': 672.537, 'train_steps_per_second': 5.336, 'train_loss': 0.3690942244096236, 'epoch': 15.0}\n",
      "{'eval_loss': 0.24480561912059784, 'eval_classification_roc_auc': 0.5693521269117261, 'eval_runtime': 0.1388, 'eval_samples_per_second': 2211.863, 'eval_steps_per_second': 21.614, 'epoch': 15.0}\n",
      "{'train_runtime': 61.2003, 'train_samples_per_second': 678.182, 'train_steps_per_second': 5.392, 'train_loss': 0.36905413540926846, 'epoch': 15.0}\n",
      "{'eval_loss': 0.24309861660003662, 'eval_classification_roc_auc': 0.5787579269696219, 'eval_runtime': 0.1416, 'eval_samples_per_second': 2211.083, 'eval_steps_per_second': 21.192, 'epoch': 15.0}\n",
      "{'train_runtime': 61.4369, 'train_samples_per_second': 677.524, 'train_steps_per_second': 5.371, 'train_loss': 0.3692512743400805, 'epoch': 15.0}\n",
      "{'eval_loss': 0.24350067973136902, 'eval_classification_roc_auc': 0.5738046568240913, 'eval_runtime': 0.1409, 'eval_samples_per_second': 2164.767, 'eval_steps_per_second': 21.293, 'epoch': 15.0}\n",
      "{'train_runtime': 61.1828, 'train_samples_per_second': 678.377, 'train_steps_per_second': 5.394, 'train_loss': 0.3689864187529593, 'epoch': 15.0}\n",
      "{'eval_loss': 0.24568341672420502, 'eval_classification_roc_auc': 0.5611888323746911, 'eval_runtime': 0.1641, 'eval_samples_per_second': 1907.676, 'eval_steps_per_second': 18.284, 'epoch': 15.0}\n",
      "{'train_runtime': 61.8905, 'train_samples_per_second': 672.559, 'train_steps_per_second': 5.332, 'train_loss': 0.36896905610055636, 'epoch': 15.0}\n",
      "{'eval_loss': 0.24331660568714142, 'eval_classification_roc_auc': 0.567577116544323, 'eval_runtime': 0.1368, 'eval_samples_per_second': 2229.302, 'eval_steps_per_second': 21.928, 'epoch': 15.0}\n",
      "{'train_runtime': 62.0834, 'train_samples_per_second': 668.778, 'train_steps_per_second': 5.315, 'train_loss': 0.36887318004261366, 'epoch': 15.0}\n",
      "{'eval_loss': 0.24379470944404602, 'eval_classification_roc_auc': 0.5572054263114317, 'eval_runtime': 0.1494, 'eval_samples_per_second': 2088.39, 'eval_steps_per_second': 20.081, 'epoch': 15.0}\n",
      "{'train_runtime': 61.9133, 'train_samples_per_second': 671.584, 'train_steps_per_second': 5.33, 'train_loss': 0.36900590838808, 'epoch': 15.0}\n",
      "{'eval_loss': 0.245749369263649, 'eval_classification_roc_auc': 0.5688018043524322, 'eval_runtime': 0.1755, 'eval_samples_per_second': 1754.848, 'eval_steps_per_second': 17.093, 'epoch': 15.0}\n",
      "{'train_runtime': 61.4758, 'train_samples_per_second': 675.632, 'train_steps_per_second': 5.368, 'train_loss': 0.36907989039565575, 'epoch': 15.0}\n",
      "{'eval_loss': 0.24393592774868011, 'eval_classification_roc_auc': 0.5697478495862104, 'eval_runtime': 0.16, 'eval_samples_per_second': 1943.147, 'eval_steps_per_second': 18.744, 'epoch': 15.0}\n",
      "{'train_runtime': 62.6264, 'train_samples_per_second': 665.374, 'train_steps_per_second': 5.269, 'train_loss': 0.3689180085153291, 'epoch': 15.0}\n",
      "{'eval_loss': 0.24381841719150543, 'eval_classification_roc_auc': 0.5783311699589917, 'eval_runtime': 0.1428, 'eval_samples_per_second': 2114.703, 'eval_steps_per_second': 21.007, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "eval_loss                         0.244524\n",
       "eval_classification_roc_auc       0.575151\n",
       "eval_runtime                      0.148300\n",
       "eval_samples_per_second        2091.036100\n",
       "eval_steps_per_second            20.378100\n",
       "epoch                            15.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metrics import multi_label_metrics\n",
    "\n",
    "classifier_result = defaultdict(list)\n",
    "\n",
    "for fold_dataset in datasets.values():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased\", \n",
    "        problem_type=\"multi_label_classification\", \n",
    "        num_labels=len(loader.index2intent.keys()), \n",
    "        id2label=loader.index2intent, \n",
    "        label2id=loader.intent2index\n",
    "    ).to('cuda')\n",
    "    \n",
    "    train_dataset = fold_dataset['train'].remove_columns(info_columns + [\"tagging_labels\"]).rename_column(\"classification_labels\", \"labels\")\n",
    "    test_dataset = fold_dataset['test'].remove_columns(info_columns + [\"tagging_labels\"]).rename_column(\"classification_labels\", \"labels\")\n",
    "\n",
    "    trainer = Trainer(model=model,\n",
    "                    args=args,\n",
    "                    train_dataset = train_dataset,\n",
    "                    eval_dataset = test_dataset,\n",
    "                    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "                    compute_metrics=multi_label_metrics,\n",
    "                    tokenizer=tokenizer)\n",
    "\n",
    "    trainer.train()\n",
    "    for name, val in trainer.evaluate().items():\n",
    "        if val != 'epoch':\n",
    "            classifier_result[name].append(val)\n",
    "\n",
    "classifier_result = pd.DataFrame(classifier_result)\n",
    "classifier_result.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для валидации задачи классификации интентов была выбрана только метрика AUC-ROC, потому что она не зависит от порога бинаризации в мульти лейбл классификации, и нам не нужно тратить драгоценные данные на подбор правильного порога для честного замера других метрик классификации.\n",
    "\n",
    "На общем фоне выделяется первый фолд, на котором значение метрики особенно высоко и достигает 0.63, остальные модели достигают качества в районе 0.57."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Одновременная классификация и поиск слотов\n",
    "\n",
    "В этом разделе мы напишем свою модель в `HuggingFace` на основе DistilBERT для одновременной классификации интентов и выделения слотов. Фактически она является объединением стандартных классов из предыдущего раздела, то есть головы и функционалы ошибок для обеих задач одинаковы, но теперь они решаются в multi task режиме и с общим backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from multitask_model import MultiTaskConfig, DistilBertForMultiTask, MultiTaskDataCollator\n",
    "\n",
    "config = MultiTaskConfig.from_pretrained(\"distilbert-base-uncased\", \n",
    "                                         num_labels_intents=len(loader.index2intent.keys()),\n",
    "                                         index2intent=loader.index2intent,\n",
    "                                         intent2index=loader.intent2index,\n",
    "                                         num_labels_tags=len(loader.index2tag.keys()),\n",
    "                                         index2tag=loader.index2tag,\n",
    "                                         tag2index=loader.tag2index\n",
    "    )\n",
    "\n",
    "args = TrainingArguments(\"distilbert-finetuned\",\n",
    "                        learning_rate=1e-5,\n",
    "                        optim=\"adamw_torch_fused\",\n",
    "                        per_device_train_batch_size=128,\n",
    "                        per_device_eval_batch_size=128,\n",
    "                        num_train_epochs=20,            # ещё больше эпох\n",
    "                        weight_decay=0.01,\n",
    "                        warmup_steps = 10,\n",
    "                        lr_scheduler_type = 'linear',\n",
    "                        evaluation_strategy=\"no\",\n",
    "                        #eval_steps=10,\n",
    "                        seed=42,\n",
    "                        fp16=True,\n",
    "                        logging_strategy='no',\n",
    "                        #logging_steps=200,\n",
    "                        save_strategy=\"no\",\n",
    "                        disable_tqdm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 83.0699, 'train_samples_per_second': 668.353, 'train_steps_per_second': 5.297, 'train_loss': 0.8417447176846591, 'epoch': 20.0}\n",
      "{'eval_loss': 0.4513086974620819, 'eval_classification_roc_auc': 0.6658139434361856, 'eval_tagger_precision': 0.4694835680751174, 'eval_tagger_recall': 0.5291005291005291, 'eval_tagger_f1': 0.49751243781094523, 'eval_tagger_accuracy': 0.929713524317122, 'eval_runtime': 0.1831, 'eval_samples_per_second': 1660.215, 'eval_steps_per_second': 16.384, 'epoch': 20.0}\n",
      "{'train_runtime': 82.2021, 'train_samples_per_second': 674.678, 'train_steps_per_second': 5.353, 'train_loss': 0.8589564930308949, 'epoch': 20.0}\n",
      "{'eval_loss': 0.3858475983142853, 'eval_classification_roc_auc': 0.6449431381950002, 'eval_tagger_precision': 0.601063829787234, 'eval_tagger_recall': 0.6174863387978142, 'eval_tagger_f1': 0.6091644204851753, 'eval_tagger_accuracy': 0.9479460645970523, 'eval_runtime': 0.1887, 'eval_samples_per_second': 1626.564, 'eval_steps_per_second': 15.895, 'epoch': 20.0}\n",
      "{'train_runtime': 81.3529, 'train_samples_per_second': 680.246, 'train_steps_per_second': 5.409, 'train_loss': 0.8567673423073509, 'epoch': 20.0}\n",
      "{'eval_loss': 0.4019838869571686, 'eval_classification_roc_auc': 0.6618369396182864, 'eval_tagger_precision': 0.602803738317757, 'eval_tagger_recall': 0.6323529411764706, 'eval_tagger_f1': 0.6172248803827752, 'eval_tagger_accuracy': 0.9413416536661466, 'eval_runtime': 0.2024, 'eval_samples_per_second': 1546.157, 'eval_steps_per_second': 14.819, 'epoch': 20.0}\n",
      "{'train_runtime': 83.1657, 'train_samples_per_second': 667.343, 'train_steps_per_second': 5.291, 'train_loss': 0.8575847972523082, 'epoch': 20.0}\n",
      "{'eval_loss': 0.40446680784225464, 'eval_classification_roc_auc': 0.6632350929194654, 'eval_tagger_precision': 0.5763546798029556, 'eval_tagger_recall': 0.5879396984924623, 'eval_tagger_f1': 0.5820895522388059, 'eval_tagger_accuracy': 0.9421869838123554, 'eval_runtime': 0.2052, 'eval_samples_per_second': 1486.633, 'eval_steps_per_second': 14.623, 'epoch': 20.0}\n",
      "{'train_runtime': 81.6236, 'train_samples_per_second': 677.99, 'train_steps_per_second': 5.391, 'train_loss': 0.8528384121981534, 'epoch': 20.0}\n",
      "{'eval_loss': 0.45102459192276, 'eval_classification_roc_auc': 0.6506443530011649, 'eval_tagger_precision': 0.5384615384615384, 'eval_tagger_recall': 0.5833333333333334, 'eval_tagger_f1': 0.5599999999999999, 'eval_tagger_accuracy': 0.9344364658133, 'eval_runtime': 0.22, 'eval_samples_per_second': 1422.553, 'eval_steps_per_second': 13.635, 'epoch': 20.0}\n",
      "{'train_runtime': 83.2283, 'train_samples_per_second': 666.84, 'train_steps_per_second': 5.287, 'train_loss': 0.8540829051624644, 'epoch': 20.0}\n",
      "{'eval_loss': 0.4214864671230316, 'eval_classification_roc_auc': 0.6438205685629733, 'eval_tagger_precision': 0.5116279069767442, 'eval_tagger_recall': 0.5670103092783505, 'eval_tagger_f1': 0.5378973105134475, 'eval_tagger_accuracy': 0.937228714524207, 'eval_runtime': 0.1986, 'eval_samples_per_second': 1535.892, 'eval_steps_per_second': 15.107, 'epoch': 20.0}\n",
      "{'train_runtime': 83.6829, 'train_samples_per_second': 661.545, 'train_steps_per_second': 5.258, 'train_loss': 0.8558679060502485, 'epoch': 20.0}\n",
      "{'eval_loss': 0.4078308343887329, 'eval_classification_roc_auc': 0.6471091316608085, 'eval_tagger_precision': 0.5217391304347826, 'eval_tagger_recall': 0.5482233502538071, 'eval_tagger_f1': 0.5346534653465347, 'eval_tagger_accuracy': 0.941890166028097, 'eval_runtime': 0.1918, 'eval_samples_per_second': 1626.71, 'eval_steps_per_second': 15.641, 'epoch': 20.0}\n",
      "{'train_runtime': 82.6407, 'train_samples_per_second': 670.856, 'train_steps_per_second': 5.324, 'train_loss': 0.8549801219593395, 'epoch': 20.0}\n",
      "{'eval_loss': 0.4153972566127777, 'eval_classification_roc_auc': 0.6602755775183539, 'eval_tagger_precision': 0.6055045871559633, 'eval_tagger_recall': 0.6197183098591549, 'eval_tagger_f1': 0.6125290023201856, 'eval_tagger_accuracy': 0.941591784338896, 'eval_runtime': 0.228, 'eval_samples_per_second': 1350.756, 'eval_steps_per_second': 13.157, 'epoch': 20.0}\n",
      "{'train_runtime': 80.8335, 'train_samples_per_second': 685.112, 'train_steps_per_second': 5.443, 'train_loss': 0.8532995744185015, 'epoch': 20.0}\n",
      "{'eval_loss': 0.43955400586128235, 'eval_classification_roc_auc': 0.6493592701956702, 'eval_tagger_precision': 0.6186046511627907, 'eval_tagger_recall': 0.6363636363636364, 'eval_tagger_f1': 0.6273584905660378, 'eval_tagger_accuracy': 0.939796233405372, 'eval_runtime': 0.2204, 'eval_samples_per_second': 1411.348, 'eval_steps_per_second': 13.614, 'epoch': 20.0}\n",
      "{'train_runtime': 82.3634, 'train_samples_per_second': 674.571, 'train_steps_per_second': 5.342, 'train_loss': 0.8558864246715199, 'epoch': 20.0}\n",
      "{'eval_loss': 0.4141448140144348, 'eval_classification_roc_auc': 0.6553163045612582, 'eval_tagger_precision': 0.48404255319148937, 'eval_tagger_recall': 0.5352941176470588, 'eval_tagger_f1': 0.5083798882681564, 'eval_tagger_accuracy': 0.9433333333333334, 'eval_runtime': 0.2, 'eval_samples_per_second': 1510.356, 'eval_steps_per_second': 15.004, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "eval_loss                         0.419304\n",
       "eval_classification_roc_auc       0.654235\n",
       "eval_tagger_precision             0.552969\n",
       "eval_tagger_recall                0.585682\n",
       "eval_tagger_f1                    0.568681\n",
       "eval_tagger_accuracy              0.939946\n",
       "eval_runtime                      0.203820\n",
       "eval_samples_per_second        1517.718400\n",
       "eval_steps_per_second            14.787900\n",
       "epoch                            20.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metrics import multitask_metrics\n",
    "\n",
    "multitask_result = defaultdict(list)\n",
    "\n",
    "for fold_dataset in datasets.values():\n",
    "    model = DistilBertForMultiTask.from_pretrained(\"distilbert-base-uncased\", config=config).to('cuda')\n",
    "    \n",
    "    train_dataset = fold_dataset['train'].rename_column(\"classification_labels\", \"label_1\").rename_column(\"tagging_labels\", \"label_2\")\n",
    "    test_dataset = fold_dataset['test'].rename_column(\"classification_labels\", \"label_1\").rename_column(\"tagging_labels\", \"label_2\")\n",
    "\n",
    "    trainer = Trainer(model=model,\n",
    "                    args=args,\n",
    "                    train_dataset=train_dataset,\n",
    "                    eval_dataset=test_dataset,\n",
    "                    data_collator=MultiTaskDataCollator(tokenizer=tokenizer),\n",
    "                    compute_metrics=multitask_metrics,\n",
    "                    tokenizer=tokenizer)\n",
    "\n",
    "    trainer.train()\n",
    "    for name, val in trainer.evaluate().items():\n",
    "        if val != 'epoch':\n",
    "            multitask_result[name].append(val)\n",
    "\n",
    "multitask_result = pd.DataFrame(multitask_result)\n",
    "multitask_result.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем заметить, что решение в multi task режиме существенно увеличило качество для обеих задач. \n",
    "\n",
    "1. Для классификации AUC-ROC вырос с 0.58 до 0.65, причём значение метрики на разных фолдах теперь различается в рамках одного процентного пункта.\n",
    "2. В теггировании F1-score тоже заметно вырос с 0.38 до 0.56 (что теперь выглядит приемлемо), но разброс значений на разных фолдах сохранился (есть разница в 20%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация с дополнительными признаками\n",
    "\n",
    "В этом разделе мы попробуем добавить дополнительные признаки к обрабатываемым словам. Теперь помимо самого текста на вход модели мы будем также подавать и BIO метки для теггирования в качестве признаков.\n",
    "\n",
    "Конечно, такая модификация потребует от нас пересмотр всей модели (а точнее её головы). Часть, отвечающая за классификацию останется прежней, то есть будет состоять из двух линейных слоёв, разделённых ReLU и dropout. Но теперь ей будет предшествовать слой BiLSTM, которому на вход будет подаваться конкатенация газетиров и эмбедингов BERT. \n",
    "\n",
    "Выбор архитектуры обусловлен необходимостью: менять эмбединги на входе берта нельзя, это испортит претрейн модели. Остаётся только добавить новые признаки к выходным эмбедингам BERT, то есть отказаться от специального токена `[CLS]`, который выдаёт общий эмбеддинг документа, а вместо него заново агрегировать сконкатенированные эмбединги реккурентой моделью. В качестве этой реккурентой модели был выбран BiLSTM, как это часто делают в смежной литературе [1](https://arxiv.org/pdf/1511.08308.pdf) и [2](https://aclanthology.org/W19-5807.pdf).\n",
    "\n",
    "LSTM оказалась очень нестабильной моделью, поэтому поначалу большая часть запусков просто расходилась в Nan или достигала плохого локального оптимума. Частично решить эту проблему помогли перенос скрытого состояния в следующий батч и хорошая инициализация весов модели через ортоганальные матрицы и метод Ксавьера.\n",
    "\n",
    "Осталось только понять, как подавать газетиры в модель. Первым проверим лобовой подход, а именно перевод индексов тегов в обучаемые эмбеддинги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gazetteers_model import GazetteerConfig, DistilBertForGazetteer, GazetteerDataCollator\n",
    "\n",
    "args = TrainingArguments(\"distilbert-finetuned\",\n",
    "                        learning_rate=1e-5,\n",
    "                        optim=\"adamw_torch_fused\",\n",
    "                        per_device_train_batch_size=128,\n",
    "                        per_device_eval_batch_size=128,\n",
    "                        num_train_epochs=20,            # ещё больше эпох\n",
    "                        weight_decay=0.01,\n",
    "                        warmup_steps=10,\n",
    "                        lr_scheduler_type='linear',\n",
    "                        evaluation_strategy=\"no\",\n",
    "                        #eval_steps=10,\n",
    "                        seed=42,\n",
    "                        fp16=True,\n",
    "                        logging_strategy='no',\n",
    "                        #logging_steps=200,\n",
    "                        save_strategy=\"no\",\n",
    "                        disable_tqdm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = GazetteerConfig.from_pretrained(\"distilbert-base-uncased\", \n",
    "                                         num_labels_intents=len(loader.index2intent.keys()),\n",
    "                                         index2intent=loader.index2intent,\n",
    "                                         intent2index=loader.intent2index,\n",
    "                                         num_labels_tags=len(loader.index2tag.keys()),\n",
    "                                         index2tag=loader.index2tag,\n",
    "                                         tag2index=loader.tag2index,\n",
    "                                         batch_size=args.per_device_train_batch_size,\n",
    "                                         use_gaz_features=True,\n",
    "                                         use_gaz_embeds=True,\n",
    "                                         gaz_embeds_dim=len(loader.index2tag.keys())+1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 99.3752, 'train_samples_per_second': 558.691, 'train_steps_per_second': 4.428, 'train_loss': 0.24322456013072621, 'epoch': 20.0}\n",
      "{'eval_loss': 0.13645081222057343, 'eval_classification_roc_auc': 0.7330673745169303, 'eval_runtime': 0.1663, 'eval_samples_per_second': 1828.034, 'eval_steps_per_second': 18.04, 'epoch': 20.0}\n",
      "{'train_runtime': 100.6947, 'train_samples_per_second': 550.774, 'train_steps_per_second': 4.37, 'train_loss': 0.2390063545920632, 'epoch': 20.0}\n",
      "{'eval_loss': 0.13722047209739685, 'eval_classification_roc_auc': 0.7179127643859314, 'eval_runtime': 0.1835, 'eval_samples_per_second': 1672.663, 'eval_steps_per_second': 16.345, 'epoch': 20.0}\n",
      "{'train_runtime': 86.1841, 'train_samples_per_second': 642.114, 'train_steps_per_second': 5.105, 'train_loss': 0.6923958518288352, 'epoch': 20.0}\n",
      "Nan output, bad try :(\n",
      "{'train_runtime': 86.8639, 'train_samples_per_second': 637.088, 'train_steps_per_second': 5.065, 'train_loss': 0.6923958518288352, 'epoch': 20.0}\n",
      "Nan output, bad try :(\n",
      "{'train_runtime': 85.7221, 'train_samples_per_second': 645.575, 'train_steps_per_second': 5.133, 'train_loss': 0.0, 'epoch': 20.0}\n",
      "Nan output, bad try :(\n",
      "{'train_runtime': 86.8427, 'train_samples_per_second': 637.244, 'train_steps_per_second': 5.067, 'train_loss': 0.6923958518288352, 'epoch': 20.0}\n",
      "Nan output, bad try :(\n",
      "{'train_runtime': 100.4059, 'train_samples_per_second': 551.163, 'train_steps_per_second': 4.382, 'train_loss': 0.24334630099209872, 'epoch': 20.0}\n",
      "{'eval_loss': 0.13428811728954315, 'eval_classification_roc_auc': 0.7139374712776425, 'eval_runtime': 0.1826, 'eval_samples_per_second': 1714.442, 'eval_steps_per_second': 16.432, 'epoch': 20.0}\n",
      "{'train_runtime': 86.7678, 'train_samples_per_second': 639.638, 'train_steps_per_second': 5.071, 'train_loss': 0.0, 'epoch': 20.0}\n",
      "Nan output, bad try :(\n",
      "{'train_runtime': 86.6758, 'train_samples_per_second': 640.317, 'train_steps_per_second': 5.076, 'train_loss': 0.6935092579234731, 'epoch': 20.0}\n",
      "{'eval_loss': 0.693047821521759, 'eval_classification_roc_auc': 0.4769351706949516, 'eval_runtime': 0.1833, 'eval_samples_per_second': 1663.528, 'eval_steps_per_second': 16.363, 'epoch': 20.0}\n",
      "{'train_runtime': 85.2691, 'train_samples_per_second': 649.004, 'train_steps_per_second': 5.16, 'train_loss': 0.6923630454323508, 'epoch': 20.0}\n",
      "{'eval_loss': 0.692115843296051, 'eval_classification_roc_auc': 0.48977407716637555, 'eval_runtime': 0.2089, 'eval_samples_per_second': 1498.145, 'eval_steps_per_second': 14.359, 'epoch': 20.0}\n",
      "{'train_runtime': 87.0011, 'train_samples_per_second': 637.923, 'train_steps_per_second': 5.057, 'train_loss': 0.6923758073286577, 'epoch': 20.0}\n",
      "{'eval_loss': 0.6920326948165894, 'eval_classification_roc_auc': 0.4742887056718769, 'eval_runtime': 0.1951, 'eval_samples_per_second': 1563.679, 'eval_steps_per_second': 15.38, 'epoch': 20.0}\n",
      "{'train_runtime': 102.2628, 'train_samples_per_second': 541.35, 'train_steps_per_second': 4.303, 'train_loss': 0.24368756034157493, 'epoch': 20.0}\n",
      "{'eval_loss': 0.13500206172466278, 'eval_classification_roc_auc': 0.7206007638810492, 'eval_runtime': 0.1981, 'eval_samples_per_second': 1574.751, 'eval_steps_per_second': 15.142, 'epoch': 20.0}\n",
      "{'train_runtime': 101.1423, 'train_samples_per_second': 548.139, 'train_steps_per_second': 4.35, 'train_loss': 0.24382679679177025, 'epoch': 20.0}\n",
      "{'eval_loss': 0.1379055380821228, 'eval_classification_roc_auc': 0.7291088352393229, 'eval_runtime': 0.2045, 'eval_samples_per_second': 1506.297, 'eval_steps_per_second': 14.672, 'epoch': 20.0}\n",
      "{'train_runtime': 85.6062, 'train_samples_per_second': 646.915, 'train_steps_per_second': 5.14, 'train_loss': 0.6935260425914418, 'epoch': 20.0}\n",
      "{'eval_loss': 0.6931836009025574, 'eval_classification_roc_auc': 0.49162616790925284, 'eval_runtime': 0.2073, 'eval_samples_per_second': 1499.967, 'eval_steps_per_second': 14.469, 'epoch': 20.0}\n",
      "{'train_runtime': 87.4024, 'train_samples_per_second': 635.681, 'train_steps_per_second': 5.034, 'train_loss': 0.6935055125843395, 'epoch': 20.0}\n",
      "{'eval_loss': 0.6928766369819641, 'eval_classification_roc_auc': 0.47370288273473304, 'eval_runtime': 0.1767, 'eval_samples_per_second': 1709.272, 'eval_steps_per_second': 16.98, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "eval_loss                         0.414412\n",
       "eval_classification_roc_auc       0.602095\n",
       "eval_runtime                      0.190630\n",
       "eval_samples_per_second        1623.077800\n",
       "eval_steps_per_second            15.818200\n",
       "epoch                            20.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gazetteer_result_embeds = defaultdict(list)\n",
    "\n",
    "folds = list(datasets.values())\n",
    "i = 0\n",
    "\n",
    "while i < len(folds):\n",
    "    try:\n",
    "        model = DistilBertForGazetteer.from_pretrained(\"distilbert-base-uncased\", config=config).to('cuda')\n",
    "\n",
    "        train_dataset = folds[i]['train'].rename_column(\"classification_labels\", \"label\").rename_column(\"tagging_labels\", \"gaz_features\")\n",
    "        test_dataset = folds[i]['test'].rename_column(\"classification_labels\", \"label\").rename_column(\"tagging_labels\", \"gaz_features\")\n",
    "\n",
    "        trainer = Trainer(model=model,\n",
    "                        args=args,\n",
    "                        train_dataset=train_dataset,\n",
    "                        eval_dataset=test_dataset,\n",
    "                        data_collator=GazetteerDataCollator(num_labels_tags=len(loader.index2tag.keys()), is_embeds=config.use_gaz_embeds, tokenizer=tokenizer),\n",
    "                        compute_metrics=multi_label_metrics,\n",
    "                        tokenizer=tokenizer)\n",
    "\n",
    "        trainer.train()\n",
    "        for name, val in trainer.evaluate().items():\n",
    "            if val != 'epoch':\n",
    "                gazetteer_result_embeds[name].append(val)\n",
    "        i += 1\n",
    "    except ValueError:\n",
    "        print(\"Nan output, bad try :(\")\n",
    "        \n",
    "\n",
    "gazetteer_result_embeds = pd.DataFrame(gazetteer_result_embeds)\n",
    "gazetteer_result_embeds.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части мы замеряем только метрики классификации. AUC-ROC здесь скачет от 0.47 до 0.73 на разных фолдах, что говорит нам о недостатке данных для обучения подобных эмбеддингов, среднее качество проигрывает multi task подходу. Кроме того, здесь мы можем заметить ту самую численную нестабильность, когда модель выучивает Nan в качестве ответа.\n",
    "\n",
    "В поисках лучшего подхода мы можеи прочитать статью [Improving Neural Named Entity Recognition with Gazetteers](https://arxiv.org/pdf/2003.03072.pdf), где авторы не выучивают эмбединги, а просто подают one-hot вектора на вход LSTM. На наших данных подавать one-hot вектора напрямую в рекуррентный слой не получилось, он также разваливался из-за большого количества нулей на входе. Поэтому сейчас мы протестируем решение, в котором эти вектора сначала обрабатываются линейным словем, а только потом идут на вход BiLSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = GazetteerConfig.from_pretrained(\"distilbert-base-uncased\", \n",
    "                                         num_labels_intents=len(loader.index2intent.keys()),\n",
    "                                         index2intent=loader.index2intent,\n",
    "                                         intent2index=loader.intent2index,\n",
    "                                         num_labels_tags=len(loader.index2tag.keys()),\n",
    "                                         index2tag=loader.index2tag,\n",
    "                                         tag2index=loader.tag2index,\n",
    "                                         batch_size=args.per_device_train_batch_size,\n",
    "                                         use_gaz_features=True,\n",
    "                                         use_gaz_embeds=False,\n",
    "                                         gaz_embeds_dim=len(loader.index2tag.keys())+1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 110.5529, 'train_samples_per_second': 502.203, 'train_steps_per_second': 3.98, 'train_loss': 0.23068960363214666, 'epoch': 20.0}\n",
      "{'eval_loss': 0.13621975481510162, 'eval_classification_roc_auc': 0.7377128062235251, 'eval_runtime': 0.219, 'eval_samples_per_second': 1387.907, 'eval_steps_per_second': 13.696, 'epoch': 20.0}\n",
      "{'train_runtime': 110.8735, 'train_samples_per_second': 500.21, 'train_steps_per_second': 3.968, 'train_loss': 0.23299232829700817, 'epoch': 20.0}\n",
      "{'eval_loss': 0.13850541412830353, 'eval_classification_roc_auc': 0.7166078827420657, 'eval_runtime': 0.2424, 'eval_samples_per_second': 1266.576, 'eval_steps_per_second': 12.377, 'epoch': 20.0}\n",
      "{'train_runtime': 109.1589, 'train_samples_per_second': 506.968, 'train_steps_per_second': 4.031, 'train_loss': 0.24163001667369496, 'epoch': 20.0}\n",
      "{'eval_loss': 0.13349366188049316, 'eval_classification_roc_auc': 0.7200070818405728, 'eval_runtime': 0.2407, 'eval_samples_per_second': 1300.374, 'eval_steps_per_second': 12.464, 'epoch': 20.0}\n",
      "{'train_runtime': 110.329, 'train_samples_per_second': 503.041, 'train_steps_per_second': 3.988, 'train_loss': 0.24052691026167436, 'epoch': 20.0}\n",
      "{'eval_loss': 0.13285690546035767, 'eval_classification_roc_auc': 0.7332829881961883, 'eval_runtime': 0.2498, 'eval_samples_per_second': 1220.798, 'eval_steps_per_second': 12.008, 'epoch': 20.0}\n",
      "{'train_runtime': 108.2584, 'train_samples_per_second': 511.184, 'train_steps_per_second': 4.064, 'train_loss': 0.2291987332430753, 'epoch': 20.0}\n",
      "{'eval_loss': 0.13744717836380005, 'eval_classification_roc_auc': 0.7255498067748885, 'eval_runtime': 0.2631, 'eval_samples_per_second': 1189.829, 'eval_steps_per_second': 11.404, 'epoch': 20.0}\n",
      "{'train_runtime': 110.4423, 'train_samples_per_second': 502.525, 'train_steps_per_second': 3.984, 'train_loss': 0.24037114923650568, 'epoch': 20.0}\n",
      "{'eval_loss': 0.1343388557434082, 'eval_classification_roc_auc': 0.7164851689899349, 'eval_runtime': 0.2288, 'eval_samples_per_second': 1333.065, 'eval_steps_per_second': 13.112, 'epoch': 20.0}\n",
      "{'train_runtime': 110.5084, 'train_samples_per_second': 500.958, 'train_steps_per_second': 3.982, 'train_loss': 0.2296426079489968, 'epoch': 20.0}\n",
      "{'eval_loss': 0.1357550024986267, 'eval_classification_roc_auc': 0.7265493057617297, 'eval_runtime': 0.2639, 'eval_samples_per_second': 1182.223, 'eval_steps_per_second': 11.368, 'epoch': 20.0}\n",
      "{'train_runtime': 109.1919, 'train_samples_per_second': 507.73, 'train_steps_per_second': 4.03, 'train_loss': 0.23753069097345525, 'epoch': 20.0}\n",
      "{'eval_loss': 0.13752034306526184, 'eval_classification_roc_auc': 0.734362658370487, 'eval_runtime': 0.2522, 'eval_samples_per_second': 1221.226, 'eval_steps_per_second': 11.895, 'epoch': 20.0}\n",
      "{'train_runtime': 107.4746, 'train_samples_per_second': 515.285, 'train_steps_per_second': 4.094, 'train_loss': 0.24057355360551314, 'epoch': 20.0}\n",
      "{'eval_loss': 0.13493843376636505, 'eval_classification_roc_auc': 0.719720520449498, 'eval_runtime': 0.2557, 'eval_samples_per_second': 1216.476, 'eval_steps_per_second': 11.734, 'epoch': 20.0}\n",
      "{'train_runtime': 109.8941, 'train_samples_per_second': 505.578, 'train_steps_per_second': 4.004, 'train_loss': 0.23744160045276988, 'epoch': 20.0}\n",
      "{'eval_loss': 0.134992316365242, 'eval_classification_roc_auc': 0.7330433427530287, 'eval_runtime': 0.2344, 'eval_samples_per_second': 1288.426, 'eval_steps_per_second': 12.799, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "eval_loss                         0.135607\n",
       "eval_classification_roc_auc       0.726332\n",
       "eval_runtime                      0.245000\n",
       "eval_samples_per_second        1260.690000\n",
       "eval_steps_per_second            12.285700\n",
       "epoch                            20.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gazetteer_result_onehot = defaultdict(list)\n",
    "\n",
    "folds = list(datasets.values())\n",
    "i = 0\n",
    "\n",
    "while i < len(folds):\n",
    "    try:\n",
    "        model = DistilBertForGazetteer.from_pretrained(\"distilbert-base-uncased\", config=config).to('cuda')\n",
    "\n",
    "        train_dataset = folds[i]['train'].rename_column(\"classification_labels\", \"label\").rename_column(\"tagging_labels\", \"gaz_features\")\n",
    "        test_dataset = folds[i]['test'].rename_column(\"classification_labels\", \"label\").rename_column(\"tagging_labels\", \"gaz_features\")\n",
    "\n",
    "        trainer = Trainer(model=model,\n",
    "                        args=args,\n",
    "                        train_dataset=train_dataset,\n",
    "                        eval_dataset=test_dataset,\n",
    "                        data_collator=GazetteerDataCollator(num_labels_tags=len(loader.index2tag.keys()), \n",
    "                                                            is_embeds=config.use_gaz_embeds, tokenizer=tokenizer),\n",
    "                        compute_metrics=multi_label_metrics,\n",
    "                        tokenizer=tokenizer)\n",
    "\n",
    "        trainer.train()\n",
    "        for name, val in trainer.evaluate().items():\n",
    "            if val != 'epoch':\n",
    "                gazetteer_result_onehot[name].append(val)\n",
    "        i += 1\n",
    "    except ValueError:\n",
    "        print(\"Nan output, bad try :(\")\n",
    "        \n",
    "\n",
    "gazetteer_result_onehot = pd.DataFrame(gazetteer_result_onehot)\n",
    "gazetteer_result_onehot.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это решение было лишено недостатков предшественника, поэтому оно выдаёт стабильное качество в районе 0.73 на всех фолдах. По сравнению с multi task подходом мы получили значимое улучшение AUC-ROC с 0.65 до 0.73. Но теперь давайте проверим, не связан ли наш прирост метрик с банальным добавлением дополнительного BiLSTM слоя в модель, и запустим ту же самую архитектуру, но без входа с газетирами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = GazetteerConfig.from_pretrained(\"distilbert-base-uncased\", \n",
    "                                         num_labels_intents=len(loader.index2intent.keys()),\n",
    "                                         index2intent=loader.index2intent,\n",
    "                                         intent2index=loader.intent2index,\n",
    "                                         num_labels_tags=len(loader.index2tag.keys()),\n",
    "                                         index2tag=loader.index2tag,\n",
    "                                         tag2index=loader.tag2index,\n",
    "                                         batch_size=args.per_device_train_batch_size,\n",
    "                                         use_gaz_features=False,\n",
    "                                         use_gaz_embeds=False,\n",
    "                                         gaz_embeds_dim=len(loader.index2tag.keys())+1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 109.4688, 'train_samples_per_second': 507.176, 'train_steps_per_second': 4.019, 'train_loss': 0.23920405994762073, 'epoch': 20.0}\n",
      "{'eval_loss': 0.13595330715179443, 'eval_classification_roc_auc': 0.7363404314485632, 'eval_runtime': 0.2158, 'eval_samples_per_second': 1408.525, 'eval_steps_per_second': 13.9, 'epoch': 20.0}\n",
      "{'train_runtime': 109.6344, 'train_samples_per_second': 505.863, 'train_steps_per_second': 4.013, 'train_loss': 0.23795346346768467, 'epoch': 20.0}\n",
      "{'eval_loss': 0.13685797154903412, 'eval_classification_roc_auc': 0.7190076841590349, 'eval_runtime': 0.2439, 'eval_samples_per_second': 1258.465, 'eval_steps_per_second': 12.298, 'epoch': 20.0}\n",
      "{'train_runtime': 108.8358, 'train_samples_per_second': 508.472, 'train_steps_per_second': 4.043, 'train_loss': 0.23872347745028408, 'epoch': 20.0}\n",
      "{'eval_loss': 0.13323919475078583, 'eval_classification_roc_auc': 0.7281413737487478, 'eval_runtime': 0.2335, 'eval_samples_per_second': 1340.288, 'eval_steps_per_second': 12.846, 'epoch': 20.0}\n",
      "{'train_runtime': 108.876, 'train_samples_per_second': 509.754, 'train_steps_per_second': 4.041, 'train_loss': 0.2390015342018821, 'epoch': 20.0}\n",
      "{'eval_loss': 0.13297392427921295, 'eval_classification_roc_auc': 0.7302258437696713, 'eval_runtime': 0.2386, 'eval_samples_per_second': 1278.471, 'eval_steps_per_second': 12.575, 'epoch': 20.0}\n",
      "{'train_runtime': 107.3213, 'train_samples_per_second': 515.648, 'train_steps_per_second': 4.1, 'train_loss': 0.2405732588334517, 'epoch': 20.0}\n",
      "{'eval_loss': 0.1370667815208435, 'eval_classification_roc_auc': 0.7182161237709612, 'eval_runtime': 0.2611, 'eval_samples_per_second': 1198.618, 'eval_steps_per_second': 11.488, 'epoch': 20.0}\n",
      "{'train_runtime': 109.4547, 'train_samples_per_second': 507.059, 'train_steps_per_second': 4.02, 'train_loss': 0.2413358514959162, 'epoch': 20.0}\n",
      "{'eval_loss': 0.13491801917552948, 'eval_classification_roc_auc': 0.7079568678227011, 'eval_runtime': 0.2234, 'eval_samples_per_second': 1364.994, 'eval_steps_per_second': 13.426, 'epoch': 20.0}\n",
      "{'train_runtime': 109.7928, 'train_samples_per_second': 504.222, 'train_steps_per_second': 4.008, 'train_loss': 0.24117355346679686, 'epoch': 20.0}\n",
      "{'eval_loss': 0.1342879831790924, 'eval_classification_roc_auc': 0.7270557877427904, 'eval_runtime': 0.2289, 'eval_samples_per_second': 1363.309, 'eval_steps_per_second': 13.109, 'epoch': 20.0}\n",
      "{'train_runtime': 108.551, 'train_samples_per_second': 510.728, 'train_steps_per_second': 4.053, 'train_loss': 0.24095535278320312, 'epoch': 20.0}\n",
      "{'eval_loss': 0.13736113905906677, 'eval_classification_roc_auc': 0.7281235078986033, 'eval_runtime': 0.2507, 'eval_samples_per_second': 1228.416, 'eval_steps_per_second': 11.965, 'epoch': 20.0}\n",
      "{'train_runtime': 108.5953, 'train_samples_per_second': 509.967, 'train_steps_per_second': 4.052, 'train_loss': 0.24007176485928622, 'epoch': 20.0}\n",
      "{'eval_loss': 0.1347348839044571, 'eval_classification_roc_auc': 0.7277818934235905, 'eval_runtime': 0.2822, 'eval_samples_per_second': 1102.126, 'eval_steps_per_second': 10.631, 'epoch': 20.0}\n",
      "{'train_runtime': 109.7711, 'train_samples_per_second': 506.144, 'train_steps_per_second': 4.008, 'train_loss': 0.23814300190318716, 'epoch': 20.0}\n",
      "{'eval_loss': 0.1347823143005371, 'eval_classification_roc_auc': 0.7278034027821194, 'eval_runtime': 0.2166, 'eval_samples_per_second': 1394.412, 'eval_steps_per_second': 13.852, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "eval_loss                         0.135218\n",
       "eval_classification_roc_auc       0.725065\n",
       "eval_runtime                      0.239470\n",
       "eval_samples_per_second        1293.762400\n",
       "eval_steps_per_second            12.609000\n",
       "epoch                            20.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gazetteer_result_clear = defaultdict(list)\n",
    "\n",
    "folds = list(datasets.values())\n",
    "i = 0\n",
    "\n",
    "while i < len(folds):\n",
    "    try:\n",
    "        model = DistilBertForGazetteer.from_pretrained(\"distilbert-base-uncased\", config=config).to('cuda')\n",
    "\n",
    "        train_dataset = folds[i]['train'].rename_column(\"classification_labels\", \"label\").rename_column(\"tagging_labels\", \"gaz_features\")\n",
    "        test_dataset = folds[i]['test'].rename_column(\"classification_labels\", \"label\").rename_column(\"tagging_labels\", \"gaz_features\")\n",
    "\n",
    "        trainer = Trainer(model=model,\n",
    "                        args=args,\n",
    "                        train_dataset=train_dataset,\n",
    "                        eval_dataset=test_dataset,\n",
    "                        data_collator=GazetteerDataCollator(num_labels_tags=len(loader.index2tag.keys()), \n",
    "                                                            is_embeds=config.use_gaz_embeds, tokenizer=tokenizer),\n",
    "                        compute_metrics=multi_label_metrics,\n",
    "                        tokenizer=tokenizer)\n",
    "\n",
    "        trainer.train()\n",
    "        for name, val in trainer.evaluate().items():\n",
    "            if val != 'epoch':\n",
    "                gazetteer_result_clear[name].append(val)\n",
    "        i += 1\n",
    "    except ValueError:\n",
    "        print(\"Nan output, bad try :(\")\n",
    "        \n",
    "\n",
    "gazetteer_result_clear = pd.DataFrame(gazetteer_result_clear)\n",
    "gazetteer_result_clear.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, качество осталось практически без изменений. Поэтому гипотеза о том, что газетиры значимо увеличивают показатели модели, не подтвердилась на наших данных.\n",
    "\n",
    "## Выводы\n",
    "\n",
    "А теперь давайте посмотрим на все полученные нами результаты. При изучении теггера стало ясно, что multitask задача в постановке NLU даёт значимый прирост в качестве теггера (что также верно и для классификации интентов). Для классификации multitask дополнительно снижает дисперсию оценки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single tagger f1:                      0.381 +- 0.047\n",
      "multitask tagger f1:                   0.569 +- 0.048\n"
     ]
    }
   ],
   "source": [
    "print(f\"single tagger f1:                      {tagger_result['eval_tagger_f1'].mean().round(3)} +- {tagger_result['eval_tagger_f1'].std().round(3)}\")\n",
    "print(f\"multitask tagger f1:                   {multitask_result['eval_tagger_f1'].mean().round(3)} +- {multitask_result['eval_tagger_f1'].std().round(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Газетиры же не предоставили нам прирост в качестве модели, дополнительные слои даже ухудшили стабильность работы всей архитектуры. Однако в ходе экспериментов мы поняли, что добавление BiLSTM на выход BERT модели является хорошим решением даже в задачах классификации документов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single classifier roc-auc:             0.575 +- 0.019\n",
      "multitask classifier roc-auc:          0.654 +- 0.008\n",
      "gazetteer embeds classifier roc-auc:   0.602 +- 0.128\n",
      "gazetteer onehot classifier roc-auc:   0.726 +- 0.008\n",
      "gazetteer clear classifier roc-auc:    0.725 +- 0.008\n"
     ]
    }
   ],
   "source": [
    "print(f\"single classifier roc-auc:             {classifier_result['eval_classification_roc_auc'].mean().round(3)} +- {classifier_result['eval_classification_roc_auc'].std().round(3)}\")\n",
    "print(f\"multitask classifier roc-auc:          {multitask_result['eval_classification_roc_auc'].mean().round(3)} +- {multitask_result['eval_classification_roc_auc'].std().round(3)}\")\n",
    "print(f\"gazetteer embeds classifier roc-auc:   {gazetteer_result_embeds['eval_classification_roc_auc'].mean().round(3)} +- {gazetteer_result_embeds['eval_classification_roc_auc'].std().round(3)}\")\n",
    "print(f\"gazetteer onehot classifier roc-auc:   {gazetteer_result_onehot['eval_classification_roc_auc'].mean().round(3)} +- {gazetteer_result_onehot['eval_classification_roc_auc'].std().round(3)}\")\n",
    "print(f\"gazetteer clear classifier roc-auc:    {gazetteer_result_clear['eval_classification_roc_auc'].mean().round(3)} +- {gazetteer_result_clear['eval_classification_roc_auc'].std().round(3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp-env)",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
