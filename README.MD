# Проект по курсу ММОТ 2023

### Сидоров Леонид 617 ВМК МГУ

Темой моего проекта было `Обучение BERT классификации с информацией из базы знаний`, постановка задачи заключается в следующем

```
Найти датасет с текстами, содержащими большое число именованых сущностей 
(можно найти готовый или разметить сущности самому, на основе базы знаний).
Провести эксперименты:
оценить качество классификации на сырых документах
оценить качество классификации при одновременном обучении разметке и классификации текстов
оценить качество классификации, когда нужные слова в тексте помечаются "маркерами"
```

В поисках подходящего набора данных я решил немного переформулирвать задачу и свёл её к задаче NLU. В ней есть два таргета:

1. интент пользователя, то есть его основное намеренние (задача multi label классификации);
2. слоты, то есть важные смысловые части запроса, которые важны для реализации интента (задача тегирования последовательности, NER).

Выделять слоты можно различными способами, но было выбрано тегирование: исходные слоты переводятся в BIO-разметку, по которой решается задача NER.

Одно наблюдение имеет следующий вид

```JSON
{
    "text": "Yes, from 25 past 23 on",
    "intents": [
      "affirm"
    ],
    "slots": {
      "time_from": {
        "text": "25 past 23",
        "span": [
          10,
          20
        ],
        "value": {
          "hour": 23,
          "minute": 25
        }
      }
    }
  },
```

В общем случае интентов может быть больше одного, в нашем примере это `affirm`, то есть подтверждение. Слотов в одном тексте также может быть много, нас интересует не конкретное его значение, а тип и расположение по токенам. То есть слотовую разметку данного текста можно представить в виде

```
O O B-time_from I-time_from I-time_from O
```

Который говорит нам, что в конце предложения клиент говорил о времени, в которое он подтвердил встречу.

## План работ

В ходе выполнения проекта были исследованы три подхода:

1. Раздельная классификация интентов и поиск слотов;
2. Одновременная классификация и поиск слотов в рамках одной модели (BERT с двумя головами);
3. Для задачи классификации теги подаются как дополнительные признаки (газетиры).

---

Газетиры (gazetteers) - это фактически добавление каких-то дополнительных признаков к токенам или их эмбедингам. Существует несколько вариантов такого добавления, классические описаны в [2].

Ясно, что при использовании BERT модификация эмбедингов сломает претрейн модели, поэтому в нашем случае стоит добавлять признаки уже к выходным эмбедингам берта (подробнее об этом можно почитать в [3]).

---

Для всех трёх вариантов качество замеряется на 10 наборах для обучения и валидации, как было предложено авторами набора данных [здесь](https://github.com/PolyAI-LDN/task-specific-datasets/tree/master/nlupp). Выборка делится на 20 фолдов, после чего последовательно 2 подряд идущих фолда используется для валидации, а все остальные для обучения, итого получаем 10 наборов данных для обучения и валидации.

Все основные модули реализованы поверх библиотеки HuggingFace. В файлах `data_loader.py`, `metrics.py`, `multitask_model.py` и `gazetteers_model.py` реализована вся внутренняя логика по сбору данных, обучению моделей и их архитектуре, а в `experiments.ipynb` все описанные выше эксперименты и более подробное описание решаемой задачи. Поставить необходимое окружение и повторить эксперименты можно с помощью команды `poetry install`.

## Литература

1. [NLU++: A Multi-Label, Slot-Rich, Generalisable Dataset for Natural Language Understanding in Task-Oriented Dialogue](https://arxiv.org/pdf/2204.13021.pdf). В статье описывается используемый набор данных и методика разбиения на фолды для оценивания результатов.

2. [Named Entity Recognition with Bidirectional LSTM-CNNs](https://arxiv.org/pdf/1511.08308.pdf) и [How to Use Gazetteers for Entity Recognition with Neural Models](https://aclanthology.org/W19-5807.pdf) Статьи об использовании газетиров и базовой постановке задачи, примеры на LSTM.

3. [Improving Neural Named Entity Recognition with Gazetteers](https://arxiv.org/pdf/2003.03072.pdf) и [GEMNET: Effective Gated Gazetteer Representations for Recognizing Complex Entities in Low-context Input](https://aclanthology.org/2021.naacl-main.118.pdf). Использование газетиров вместе с BERT.
