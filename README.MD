# Проект по курсу ММОТ 2023

### Сидоров Леонид 617 ВМК МГУ

Темой моего проекта было `Обучение BERT классификации с информацией из базы знаний`, постановка задачи заключается в следующем

```
Найти датасет с текстами, содержащими большое число именованых сущностей 
(можно найти готовый или разметить сущности самому, на основе базы знаний).
Провести эксперименты:
оценить качество классификации на сырых документах
оценить качество классификации при одновременном обучении разметке и классификации текстов
оценить качество классификации, когда нужные слова в тексте помечаются "маркерами"
```

В поисках подходящего набора данных я решил немного переформулирвать задачу и свёл её к постановке NLU: по входному запросу необходимо

1. Выделить интент пользователя, то есть его основное намеренние (задача multi label классификации);
2. В запросе выделить его важные смысловые части, которые важны для реализации интента, то есть слоты (задача тегирования последовательности).

Выделять слоты можно различными способами, но поскольку в изначальной постановке задачи фигурировала именно задача NER, было выбранно тегирование.

В ходе выполнения проекта я планирую сравнить три подхода:

1. Раздельная классификация интентов и поиск слотов;
2. Одновременная классификация и поиск слотов в рамках одной модели (BERT с двумя головами);
3. Для задачи классификации теги подаются как дополнительные признаки (газетиры), а для задачи поиска слотов обучается своя модель на каждый интент (в случае нескольких интентов можно использовать голосование).

Для всех трёх вариантов планируется замерить качество в задачах тегирования и классификации и сравнить их, качество будет замеряться на 10 фолдах, как было предложено авторами набора данных [здесь](https://github.com/PolyAI-LDN/task-specific-datasets/tree/master/nlupp). На данный момент я успел только реализовать класс по выгрузке и предобработке набора данных в правильном формате, а также выполнить первый пункт предложенного плана с помощью Hugging Face. 

## Литература

1. [NLU++: A Multi-Label, Slot-Rich, Generalisable Dataset for Natural Language Understanding in Task-Oriented Dialogue](https://arxiv.org/pdf/2204.13021.pdf). В статье описывается используемый набор данных и методика разбиения на фолды для оценивания результатов.

2. [Named Entity Recognition with Bidirectional LSTM-CNNs](https://arxiv.org/pdf/1511.08308.pdf) и [How to Use Gazetteers for Entity Recognition with Neural Models](https://aclanthology.org/W19-5807.pdf) Статьи об использовании газетиров и базовой постановке задачи, примеры на LSTM.

3. [Improving Neural Named Entity Recognition with Gazetteers](https://arxiv.org/pdf/2003.03072.pdf) и [GEMNET: Effective Gated Gazetteer Representations for Recognizing Complex Entities in Low-context Input](https://aclanthology.org/2021.naacl-main.118.pdf). Использование газетиров вместе с BERT (ясно, что базовая модификация эмбеддингов как во втором пункте испортит претрейн).
