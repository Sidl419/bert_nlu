# Проект по курсу ММОТ 2023

### Сидоров Леонид 617 ВМК МГУ

Темой моего проекта было `Обучение BERT классификации с информацией из базы знаний`, постановка задачи заключается в следующем

```
Найти датасет с текстами, содержащими большое число именованых сущностей 
(можно найти готовый или разметить сущности самому, на основе базы знаний).
Провести эксперименты:
оценить качество классификации на сырых документах
оценить качество классификации при одновременном обучении разметке и классификации текстов
оценить качество классификации, когда нужные слова в тексте помечаются "маркерами"
```

В поисках подходящего набора данных я решил немного переформулирвать задачу и свёл её к задаче NLU. В ней есть два таргета:

1. интент пользователя, то есть его основное намеренние (задача multi label классификации);
2. слоты, то есть важные смысловые части запроса, которые важны для реализации интента (задача тегирования последовательности, NER).

Выделять слоты можно различными способами, но было выбрано тегирование: исходные слоты переводятся в BIO-разметку, по которой решается задача NER.

Одно наблюдение имеет следующий вид

```JSON
{
    "text": "Yes, from 25 past 23 on",
    "intents": [
      "affirm"
    ],
    "slots": {
      "time_from": {
        "text": "25 past 23",
        "span": [
          10,
          20
        ],
        "value": {
          "hour": 23,
          "minute": 25
        }
      }
    }
  },
```

В общем случае интентов может быть больше одного, в нашем примере это `affirm`, то есть подтверждение. Слотов в одном тексте также может быть много, нас интересует не конкретное его значение, а тип и расположение по токенам. То есть слотовую разметку данного текста можно представить в виде

```
O O B-time_from I-time_from I-time_from O
```

Который говорит нам, что в конце предложения клиент говорил о времени, в которое он подтвердил встречу.


## План работ

В ходе выполнения проекта я планирую сравнить три подхода:

1. Раздельная классификация интентов и поиск слотов;
2. Одновременная классификация и поиск слотов в рамках одной модели (BERT с двумя головами);
3. Для задачи классификации теги подаются как дополнительные признаки (газетиры), а для задачи поиска слотов обучается своя модель на каждый интент (в случае нескольких интентов можно использовать голосование).

Для всех трёх вариантов планируется замерить качество в задачах тегирования и классификации и сравнить их, качество будет замеряться на 10 фолдах, как было предложено авторами набора данных [здесь](https://github.com/PolyAI-LDN/task-specific-datasets/tree/master/nlupp).

На данный момент я успел только реализовать класс по выгрузке и предобработке набора данных в правильном формате, а также выполнить первый пункт предложенного плана с помощью Hugging Face. В файле `data_loader.py` реализована вся логика по сбору и подготовке данных, а в `experiments.ipynb` эксперименты по обучению моделей и замеру качества в различных задачах. Поставить необходимое окружение и повторить эксперименты можно с помощью команды `poetry install`.

## Литература

1. [NLU++: A Multi-Label, Slot-Rich, Generalisable Dataset for Natural Language Understanding in Task-Oriented Dialogue](https://arxiv.org/pdf/2204.13021.pdf). В статье описывается используемый набор данных и методика разбиения на фолды для оценивания результатов.

2. [Named Entity Recognition with Bidirectional LSTM-CNNs](https://arxiv.org/pdf/1511.08308.pdf) и [How to Use Gazetteers for Entity Recognition with Neural Models](https://aclanthology.org/W19-5807.pdf) Статьи об использовании газетиров и базовой постановке задачи, примеры на LSTM.

3. [Improving Neural Named Entity Recognition with Gazetteers](https://arxiv.org/pdf/2003.03072.pdf) и [GEMNET: Effective Gated Gazetteer Representations for Recognizing Complex Entities in Low-context Input](https://aclanthology.org/2021.naacl-main.118.pdf). Использование газетиров вместе с BERT (ясно, что базовая модификация эмбеддингов как во втором пункте испортит претрейн).
